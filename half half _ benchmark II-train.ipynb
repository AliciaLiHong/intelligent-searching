{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set is from coco train 2017, there are totally 118,287 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the whole dataset into train set (58K) and test set (60K)\n",
    "\n",
    "Divide each set into two non-overlapping parts: part-A (~30%) and part-B (~70%)\n",
    "\n",
    "the whole image dataset, 118287 images            //\n",
    "train - 57960 images, test - 60327 images         //\n",
    "train_part_A - 17388, train_part_B - 40572 images       //\n",
    "test_part_A - 18098, test_part_B - 42229 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part_A = np.load('train_part_A.npy')  #train_part_A - 17388 images\n",
    "train_part_B = np.load('train_part_B.npy')  #train_part_B - 40572 images   \n",
    "\n",
    "#test_part_A = np.load('test_part_A.npy')    #test_part_A - 18098 images\n",
    "#test_part_B = np.load('test_part_B.npy')    #test_part_B - 42229 images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop out halves for all images in both parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_A_left = []\n",
    "im_A_right = []\n",
    "hist_A_left = []\n",
    "hist_A_right = []\n",
    "\n",
    "H_least = 300   # images larger than (H_least, W_least) are not resized\n",
    "W_least = 500   # others resized to (H_least, W_least)\n",
    "margin = 10\n",
    "\n",
    "for i in range(max(len(train_part_A), 120)): \n",
    "    im = cv2.imread(train_part_A[i])\n",
    "    \n",
    "    if im.shape[0] > H_least and im.shape[1] > W_least: # Try to find images that are large enough to have 224x224 crops from the two halves\n",
    "        left_x = random.randint(0, im.shape[1]//2 - 224 - margin//2)  # Crop out boundaries (rather than simply cut image into halves) to avoid simply continuity clue\n",
    "        left_y = random.randint(0, im.shape[0] - 224)\n",
    "        im_l = im[left_y:left_y+224, left_x:left_x+224]  # y:y+h, x:x+w\n",
    "        im_A_left.append(im_l) \n",
    "        \n",
    "        \n",
    "        right_x = random.randint(im.shape[1]//2 + margin//2, im.shape[1]-224)\n",
    "        right_y = random.randint(0, im.shape[0] - 224)\n",
    "        im_r = im[right_y:right_y+224, right_x:right_x+224]\n",
    "        #print(im.shape,im_l.shape,im_r.shape)\n",
    "        im_A_right.append(im_r)\n",
    "        \n",
    "\n",
    "        hist_A_left.append(cv2.calcHist([im_l], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]))\n",
    "        hist_A_right.append(cv2.calcHist([im_r], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]))  \n",
    "    \n",
    "    else:\n",
    "        im = cv2.resize(im, (W_least, H_least))  # resize the images that are not large enough to (300, 500)\n",
    "        left_x = random.randint(0, im.shape[1]//2 - 224)  # Crop out boundaries (rather than simply cut image into halves) to avoid simply continuity clue\n",
    "        left_y = random.randint(0, im.shape[0] - 224)\n",
    "        im_l = im[left_y:left_y+224, left_x:left_x+224]\n",
    "        \n",
    "        im_A_left.append(im_l) # y:y+h, x:x+w\n",
    "        \n",
    "        \n",
    "        right_x = random.randint(im.shape[1]//2, im.shape[1]-224)\n",
    "        right_y = random.randint(0, im.shape[0] - 224)\n",
    "        im_r = im[right_y:right_y+224, right_x:right_x+224]\n",
    "        #print(im.shape,im_l.shape,im_r.shape)\n",
    "        im_A_right.append(im_r)\n",
    "        \n",
    "\n",
    "        hist_A_left.append(cv2.calcHist([im_l], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]))\n",
    "        hist_A_right.append(cv2.calcHist([im_r], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_B_left = []\n",
    "im_B_right = []\n",
    "hist_B_left = []\n",
    "hist_B_right = []\n",
    "\n",
    "for i in range(max(len(train_part_B), 280)): \n",
    "    im = cv2.imread(train_part_B[i])\n",
    "    \n",
    "    if im.shape[0] > H_least and im.shape[1] > W_least: # Try to find images that are large enough to have 224x224 crops from the two halves\n",
    "        left_x = random.randint(0, im.shape[1]//2 - 224 - margin//2)  # Crop out boundaries (rather than simply cut image into halves) to avoid simply continuity clue\n",
    "        left_y = random.randint(0, im.shape[0] - 224)\n",
    "        im_l = im[left_y:left_y+224, left_x:left_x+224]\n",
    "        im_B_left.append(im_l) # y:y+h, x:x+w\n",
    "        \n",
    "        \n",
    "        right_x = random.randint(im.shape[1]//2 + margin//2, im.shape[1]-224)\n",
    "        right_y = random.randint(0, im.shape[0] - 224)\n",
    "        im_r = im[right_y:right_y+224, right_x:right_x+224]\n",
    "        im_B_right.append(im_r)\n",
    "        #print(im.shape,im_l.shape,im_r.shape)\n",
    "\n",
    "        hist_B_left.append(cv2.calcHist([im_l], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]))\n",
    "        hist_B_right.append(cv2.calcHist([im_r], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]))  \n",
    "    \n",
    "    else:\n",
    "        im = cv2.resize(im, (W_least, H_least))  # resize the images that are not large enough to (300, 500)\n",
    "        left_x = random.randint(0, im.shape[1]//2 - 224)  # Crop out boundaries (rather than simply cut image into halves) to avoid simply continuity clue\n",
    "        left_y = random.randint(0, im.shape[0] - 224)\n",
    "        im_l = im[left_y:left_y+224, left_x:left_x+224]\n",
    "        im_B_left.append(im_l) # y:y+h, x:x+w\n",
    "        \n",
    "        \n",
    "        right_x = random.randint(im.shape[1]//2, im.shape[1]-224)\n",
    "        right_y = random.randint(0, im.shape[0] - 224)\n",
    "        im_r = im[right_y:right_y+224, right_x:right_x+224]\n",
    "        im_B_right.append(im_r)\n",
    "        #print(im.shape,im_l.shape,im_r.shape)\n",
    "\n",
    "        hist_B_left.append(cv2.calcHist([im_l], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]))\n",
    "        hist_B_right.append(cv2.calcHist([im_r], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tBuild a task case for each image in part-A:\n",
    "\n",
    "o\trandomly pick a half (left/right) as the reference image and the other half as the ground-truth target image \n",
    "\n",
    "o\tfrom all images in part-B (only consider the \"correct\" side, e.g. if the reference image is from the left side, use only right side of the part-B images), randomly sample (#Choices-1) of them that are among the top K in terms of color histogram similarity from the GT target image. \n",
    "\n",
    "o\tsave the task as task_i = <ref_img, <choices>, gt_idx>, where <choices> are shuffled (#Choices-1) image halves from part-B together with the target image, and 'gt_idx' is the index of the target image within <choices>. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ref = len(im_A_left)\n",
    "num_B = len(im_B_left)\n",
    "compare_method = 3 # means that the smaller the compareHist, the similar\n",
    "num_choice = 10\n",
    "K = 100\n",
    "\n",
    "task_ref = []  # \n",
    "task_tgt = []  #\n",
    "task_choices_minus_1 = []\n",
    "\n",
    "for i_ref in range(num_ref):\n",
    "    lr = np.random.randint(2)\n",
    "    if lr == 0:  # pick left half as the reference image\n",
    "        task_ref.append(-1*i_ref)  # negative value means ref images are picked from left\n",
    "        task_tgt.append(i_ref)     # positive value means tgt images are picked from right\n",
    "        \n",
    "        hist_Comp = []\n",
    "        for j in range(num_B):     # ref in A_left, choices in B_right\n",
    "            halfi_halfj = cv2.compareHist(hist_A_left[i_ref], hist_B_right[j], compare_method)\n",
    "            hist_Comp.append(halfi_halfj)\n",
    "        \n",
    "        # the top K in terms of color histogram similarity from the GT target image.\n",
    "        matchest_topK = np.argpartition(np.array(hist_Comp),K)[:K]  \n",
    "        # randomly sample (#Choices-1) among the top K\n",
    "        arg_choices_minus_1 = np.random.choice(K, num_choice-1, replace=False)\n",
    "        choices_minus_1 = matchest_topK[arg_choices_minus_1]\n",
    "        task_choices_minus_1.append(choices_minus_1)      # choices in B_right, positive\n",
    "    \n",
    "    else:        # pick right half as the reference image\n",
    "        task_ref.append(i_ref)          # positive value means ref images are picked from right\n",
    "        task_tgt.append(-1*i_ref)       # negative value means tgt images are picked from left\n",
    "        \n",
    "        hist_Comp = []\n",
    "        for j in range(num_B):         # ref in A_right, choices in B_left\n",
    "            halfi_halfj = cv2.compareHist(hist_A_right[i_ref], hist_B_left[j], compare_method)\n",
    "            hist_Comp.append(halfi_halfj)\n",
    "        \n",
    "        matchest_topK = np.argpartition(np.array(hist_Comp),K)[:K]  \n",
    "        arg_choices_minus_1 = np.random.choice(K, num_choice-1, replace=False)\n",
    "        choices_minus_1 = matchest_topK[arg_choices_minus_1]\n",
    "        task_choices_minus_1.append(choices_minus_1 * (-1))  # choices in B_left, negative value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 [-37491 -38930  -9399 -26972 -10295 -40537  -5656 -28221 -19985]\n",
      "-1 1 [20929 37883 27297 23113  5603 38852 28983 40253 12958]\n",
      "2 -2 [ -6637 -10435 -37796 -25569 -38822 -20852 -16199 -15416 -23407]\n",
      "3 -3 [-31382 -20597 -33625 -18736 -17970 -35223 -25690  -3380 -39960]\n",
      "4 -4 [-40423 -34410  -9415 -35706  -2311 -29356  -2269 -21690 -21159]\n"
     ]
    }
   ],
   "source": [
    "for i in range(min(num_ref,5)):\n",
    "    print(task_ref[i], task_tgt[i], task_choices_minus_1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''np.save('train_im_A_left', im_A_left)\n",
    "np.save('train_im_B_left', im_B_left)\n",
    "np.save('train_im_A_right', im_A_right)\n",
    "np.save('train_im_B_right', im_B_right)\n",
    "\n",
    "np.save('train_hist_A_left', hist_A_left)\n",
    "np.save('train_hist_B_left', hist_B_left)\n",
    "np.save('train_hist_A_right', hist_A_right)\n",
    "np.save('train_hist_B_right', hist_B_right)\n",
    "\n",
    "np.save('train_task_choices_minus_1',task_choices_minus_1 )'''\n",
    "# all deleted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''np.save('train_task_ref.npy',task_ref )\n",
    "np.save('train_task_tgt.npy',task_tgt )'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few task samples once you are done with this. We might also want to use more carefully picked images (indoor scenes, e.g. from topic models, or scenes in general) later, depending on how challenging this initial benchmark looks like. \n",
    "\n",
    "A good folder structure can be having one folder for each sample containing the reference image together with all choices: \n",
    "sample_id/\n",
    " - reference.png\n",
    " - choice_0.png\n",
    " - choice_1.png\n",
    " ...\n",
    " - choice_9.png\n",
    "\n",
    "The ground-truth can be saved in a single .txt file with two columns: sample_id and true_choice_idx. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_num = len(im_A_left)\n",
    "samples_num = 16 # take samples_num of samples to show the results\n",
    "len_sample_id = 9  # e.g 000000666\n",
    "\n",
    "gt_train = []\n",
    "\n",
    "import os\n",
    "if not os.path.exists('./task_train'):\n",
    "    os.mkdir('./task_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(max(task_num, samples_num)):\n",
    "    str_i = '0'*(len_sample_id-len(str(i))) + str(i) \n",
    "    \n",
    "    if task_ref[i] < 0 or (task_ref[i] == 0 and sum(task_choices_minus_1[i])>0): # ref in A_left, ground_truth in A_right, target choices in B_right\n",
    "        if not os.path.exists('./task_train/'+str_i):\n",
    "            os.mkdir('./task_train/'+str_i)\n",
    "            \n",
    "        cv2.imwrite('./task_train/'+str_i+\"/reference\" + \".jpg\", im_A_left[i])\n",
    "        gt_id = random.randint(0, num_choice-1) # randomly set up gt_id from {0, 1, 2, ...., num_choice-1}\n",
    "        \n",
    "        cv2.imwrite('./task_train/'+str_i+\"/choice_\" + str(gt_id) + \".jpg\", im_A_right[i])\n",
    "        gt_train.append([str_i, str(gt_id)])\n",
    "        \n",
    "        for choice_i in range(num_choice):\n",
    "            if choice_i < gt_id:\n",
    "                cv2.imwrite('./task_train/'+str_i+\"/choice_\"+str(choice_i)+ \".jpg\", im_B_right[task_choices_minus_1[i][choice_i]])\n",
    "            elif choice_i > gt_id:\n",
    "                cv2.imwrite('./task_train/'+str_i+\"/choice_\"+str(choice_i)+ \".jpg\", im_B_right[task_choices_minus_1[i][choice_i-1]])\n",
    "        \n",
    "    \n",
    "    elif task_ref[i] > 0 or (task_ref[i] == 0 and sum(task_choices_minus_1[i])<0) : # ref in A_right, ground_truth in A_left, target choices in B_left\n",
    "        if not os.path.exists('./task_train/'+str_i):\n",
    "            os.mkdir('./task_train/'+str_i)\n",
    "            \n",
    "        cv2.imwrite('./task_train/'+str_i+\"/reference\" + \".jpg\", im_A_right[i])\n",
    "        gt_id = random.randint(0, num_choice-1) # randomly set up gt_id from {0, 1, 2, ...., num_choice-1}\n",
    "        \n",
    "        cv2.imwrite('./task_train/'+str_i+\"/choice_\" + str(gt_id) + \".jpg\", im_A_left[i])\n",
    "        gt_train.append([str_i, str(gt_id)])\n",
    "        \n",
    "        for choice_i in range(num_choice):\n",
    "            if choice_i < gt_id:\n",
    "                cv2.imwrite('./task_train/'+str_i+\"/choice_\"+str(choice_i)+ \".jpg\", im_B_left[task_choices_minus_1[i][choice_i] * (-1)])\n",
    "            elif choice_i > gt_id:\n",
    "                cv2.imwrite('./task_train/'+str_i+\"/choice_\"+str(choice_i)+ \".jpg\", im_B_left[task_choices_minus_1[i][choice_i-1] * (-1)])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['000000000', '3'], ['000000001', '4'], ['000000002', '7'], ['000000003', '6'], ['000000004', '8'], ['000000005', '4'], ['000000006', '3'], ['000000007', '6'], ['000000008', '6'], ['000000009', '2'], ['000000010', '5'], ['000000011', '3'], ['000000012', '6'], ['000000013', '2'], ['000000014', '7'], ['000000015', '4']]\n"
     ]
    }
   ],
   "source": [
    "print(gt_train[:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"gt_train.csv\",\"w+\") as my_csv:            # writing the file as my_csv\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',')  # using the csv module to write the file\n",
    "    csvWriter.writerows(gt_train)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
