{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the whole dataset into train set (58K) and test set (60K)\n",
    "\n",
    "Divide each set into two non-overlapping parts: part-A (~30%) and part-B (~70%)\n",
    "\n",
    "the whole image dataset, 118287 images            //\n",
    "train - 57960 images, test - 60327 images         //\n",
    "train_part_A - 17388, train_part_B - 40572 images       //\n",
    "test_part_A - 18098, test_part_B - 42229 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part_A = np.load('train_part_A.npy')  #train_part_A - 29757 images\n",
    "train_part_B = np.load('train_part_B.npy')  #train_part_B - 69435 images   \n",
    "\n",
    "#test_part_A = np.load('test_part_A.npy')    #test_part_A - 30972 images\n",
    "#test_part_B = np.load('test_part_B.npy')    #test_part_B - 72270 images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop out halves for all images in both parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29757\n"
     ]
    }
   ],
   "source": [
    "im_A_left = []\n",
    "im_A_right = []\n",
    "hist_A_left = []\n",
    "hist_A_right = []\n",
    "\n",
    "SIZE = 224\n",
    "margin = 0.1\n",
    "H_least = int(SIZE * (1+margin))\n",
    "W_least = H_least * 2  \n",
    "\n",
    "\n",
    "for i in range(max(len(train_part_A), 120)): \n",
    "    im = cv2.imread(train_part_A[i])\n",
    "    \n",
    "    im = cv2.resize(im, (W_least, H_least))  # resize the images that are not large enough to (300, 500)\n",
    "    left_x = random.randint(0, im.shape[1]//2 - SIZE)  # Crop out boundaries (rather than simply cut image into halves) to avoid simply continuity clue\n",
    "    left_y = random.randint(0, im.shape[0] - SIZE)\n",
    "    im_l = im[left_y:left_y+SIZE, left_x:left_x+SIZE]\n",
    "        \n",
    "    im_A_left.append(im_l) # y:y+h, x:x+w\n",
    "        \n",
    "        \n",
    "    right_x = random.randint(im.shape[1]//2, im.shape[1]-SIZE)\n",
    "    right_y = random.randint(0, im.shape[0] - SIZE)\n",
    "    im_r = im[right_y:right_y+SIZE, right_x:right_x+SIZE]\n",
    "    #print(im.shape,im_l.shape,im_r.shape)\n",
    "    im_A_right.append(im_r)\n",
    "        \n",
    "\n",
    "    hist_A_left.append(cv2.calcHist([im_l], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]))\n",
    "    hist_A_right.append(cv2.calcHist([im_r], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]))\n",
    "    \n",
    "    \n",
    "print(len(im_A_left))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69435\n"
     ]
    }
   ],
   "source": [
    "im_B_left = []\n",
    "im_B_right = []\n",
    "hist_B_left = []\n",
    "hist_B_right = []\n",
    "\n",
    "for i in range(max(len(train_part_B), 280)): \n",
    "    im = cv2.imread(train_part_B[i])    \n",
    "    im = cv2.resize(im, (W_least, H_least))  # resize the images that are not large enough to (300, 500)\n",
    "    left_x = random.randint(0, im.shape[1]//2 - 224)  # Crop out boundaries (rather than simply cut image into halves) to avoid simply continuity clue\n",
    "    left_y = random.randint(0, im.shape[0] - 224)\n",
    "    im_l = im[left_y:left_y+224, left_x:left_x+224]\n",
    "    im_B_left.append(im_l) # y:y+h, x:x+w\n",
    "        \n",
    "        \n",
    "    right_x = random.randint(im.shape[1]//2, im.shape[1]-224)\n",
    "    right_y = random.randint(0, im.shape[0] - 224)\n",
    "    im_r = im[right_y:right_y+224, right_x:right_x+224]\n",
    "    im_B_right.append(im_r)\n",
    "        #print(im.shape,im_l.shape,im_r.shape)\n",
    "\n",
    "    hist_B_left.append(cv2.calcHist([im_l], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]))\n",
    "    hist_B_right.append(cv2.calcHist([im_r], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]))  \n",
    "    \n",
    "print(len(hist_B_left))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tBuild a task case for each image in part-A:\n",
    "\n",
    "o\trandomly pick a half (left/right) as the reference image and the other half as the ground-truth target image \n",
    "\n",
    "o\tfrom all images in part-B (only consider the \"correct\" side, e.g. if the reference image is from the left side, use only right side of the part-B images), randomly sample (#Choices-1) of them that are among the top K in terms of color histogram similarity from the GT target image. \n",
    "\n",
    "o\tsave the task as task_i = <ref_img, <choices>, gt_idx>, where <choices> are shuffled (#Choices-1) image halves from part-B together with the target image, and 'gt_idx' is the index of the target image within <choices>. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29757\n"
     ]
    }
   ],
   "source": [
    "num_ref = len(im_A_left)\n",
    "print(num_ref)\n",
    "num_B = len(im_B_left)\n",
    "compare_method = 3 # means that the smaller the compareHist, the similar\n",
    "num_choice = 10\n",
    "K = 100\n",
    "\n",
    "task_ref = []  # \n",
    "task_tgt = []  #\n",
    "task_choices_minus_1 = []\n",
    "\n",
    "for i_ref in range(num_ref):\n",
    "    lr = np.random.randint(2)\n",
    "    if lr == 0:  # pick left half as the reference image\n",
    "        task_ref.append(-1*i_ref)  # negative value means ref images are picked from left\n",
    "        task_tgt.append(i_ref)     # positive value means tgt images are picked from right\n",
    "        \n",
    "        hist_Comp = []\n",
    "        for j in range(num_B):     # ref in A_left, choices in B_right\n",
    "            halfi_halfj = cv2.compareHist(hist_A_left[i_ref], hist_B_right[j], compare_method)\n",
    "            hist_Comp.append(halfi_halfj)\n",
    "        \n",
    "        # the top K in terms of color histogram similarity from the GT target image.\n",
    "        matchest_topK = np.argpartition(np.array(hist_Comp),K)[:K]  \n",
    "        # randomly sample (#Choices-1) among the top K\n",
    "        arg_choices_minus_1 = np.random.choice(K, num_choice-1, replace=False)\n",
    "        choices_minus_1 = matchest_topK[arg_choices_minus_1]\n",
    "        task_choices_minus_1.append(choices_minus_1)      # choices in B_right, positive\n",
    "    \n",
    "    else:        # pick right half as the reference image\n",
    "        task_ref.append(i_ref)          # positive value means ref images are picked from right\n",
    "        task_tgt.append(-1*i_ref)       # negative value means tgt images are picked from left\n",
    "        \n",
    "        hist_Comp = []\n",
    "        for j in range(num_B):         # ref in A_right, choices in B_left\n",
    "            halfi_halfj = cv2.compareHist(hist_A_right[i_ref], hist_B_left[j], compare_method)\n",
    "            hist_Comp.append(halfi_halfj)\n",
    "        \n",
    "        matchest_topK = np.argpartition(np.array(hist_Comp),K)[:K]  \n",
    "        arg_choices_minus_1 = np.random.choice(K, num_choice-1, replace=False)\n",
    "        choices_minus_1 = matchest_topK[arg_choices_minus_1]\n",
    "        task_choices_minus_1.append(choices_minus_1 * (-1))  # choices in B_left, negative value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 [-23134  -2334 -57183 -44087 -23188 -18203 -30691 -67231 -15543]\n",
      "1 -1 [-52323 -24988 -60274 -14685  -3763 -33755 -68610   -141 -41427]\n",
      "2 -2 [-18096 -59367 -27658 -53748 -48471 -15750 -61249  -1025  -4429]\n",
      "3 -3 [-46939 -67862 -30855 -51176 -42730 -40369 -21936  -2395 -10888]\n",
      "4 -4 [-39997 -44314 -35535 -44420 -33556  -1347  -8764 -67861 -41674]\n"
     ]
    }
   ],
   "source": [
    "for i in range(min(num_ref,5)):\n",
    "    print(task_ref[i], task_tgt[i], task_choices_minus_1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"np.save('train_im_A_left', im_A_left)\\nnp.save('train_im_B_left', im_B_left)\\nnp.save('train_im_A_right', im_A_right)\\nnp.save('train_im_B_right', im_B_right)\\n\\nnp.save('train_hist_A_left', hist_A_left)\\nnp.save('train_hist_B_left', hist_B_left)\\nnp.save('train_hist_A_right', hist_A_right)\\nnp.save('train_hist_B_right', hist_B_right)\\n\\nnp.save('train_task_choices_minus_1',task_choices_minus_1 )\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''np.save('train_im_A_left', im_A_left)\n",
    "np.save('train_im_B_left', im_B_left)\n",
    "np.save('train_im_A_right', im_A_right)\n",
    "np.save('train_im_B_right', im_B_right)\n",
    "\n",
    "np.save('train_hist_A_left', hist_A_left)\n",
    "np.save('train_hist_B_left', hist_B_left)\n",
    "np.save('train_hist_A_right', hist_A_right)\n",
    "np.save('train_hist_B_right', hist_B_right)\n",
    "\n",
    "np.save('train_task_choices_minus_1',task_choices_minus_1 )'''\n",
    "# all deleted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"np.save('train_task_ref.npy',task_ref )\\nnp.save('train_task_tgt.npy',task_tgt )\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''np.save('train_task_ref.npy',task_ref )\n",
    "np.save('train_task_tgt.npy',task_tgt )'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few task samples once you are done with this. We might also want to use more carefully picked images (indoor scenes, e.g. from topic models, or scenes in general) later, depending on how challenging this initial benchmark looks like. \n",
    "\n",
    "A good folder structure can be having one folder for each sample containing the reference image together with all choices: \n",
    "sample_id/\n",
    " - reference.png\n",
    " - choice_0.png\n",
    " - choice_1.png\n",
    " ...\n",
    " - choice_9.png\n",
    "\n",
    "The ground-truth can be saved in a single .txt file with two columns: sample_id and true_choice_idx. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29757\n"
     ]
    }
   ],
   "source": [
    "task_num = len(im_A_left)\n",
    "print(task_num)\n",
    "\n",
    "samples_num = 16 # take samples_num of samples to show the results\n",
    "len_sample_id = 9  # e.g 000000666\n",
    "\n",
    "gt_train = []\n",
    "\n",
    "import os\n",
    "if not os.path.exists('./task_train'):\n",
    "    os.mkdir('./task_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(max(task_num, samples_num)):\n",
    "    str_i = '0'*(len_sample_id-len(str(i))) + str(i) \n",
    "    \n",
    "    if task_ref[i] < 0 or (task_ref[i] == 0 and sum(task_choices_minus_1[i])>0): # ref in A_left, ground_truth in A_right, target choices in B_right\n",
    "        if not os.path.exists('./task_train/'+str_i):\n",
    "            os.mkdir('./task_train/'+str_i)\n",
    "            \n",
    "        cv2.imwrite('./task_train/'+str_i+\"/reference\" + \".jpg\", im_A_left[i])\n",
    "        gt_id = random.randint(0, num_choice-1) # randomly set up gt_id from {0, 1, 2, ...., num_choice-1}\n",
    "        \n",
    "        cv2.imwrite('./task_train/'+str_i+\"/choice_\" + str(gt_id) + \".jpg\", im_A_right[i])\n",
    "        gt_train.append([str_i, str(gt_id)])\n",
    "        \n",
    "        for choice_i in range(num_choice):\n",
    "            if choice_i < gt_id:\n",
    "                cv2.imwrite('./task_train/'+str_i+\"/choice_\"+str(choice_i)+ \".jpg\", im_B_right[task_choices_minus_1[i][choice_i]])\n",
    "            elif choice_i > gt_id:\n",
    "                cv2.imwrite('./task_train/'+str_i+\"/choice_\"+str(choice_i)+ \".jpg\", im_B_right[task_choices_minus_1[i][choice_i-1]])\n",
    "        \n",
    "    \n",
    "    elif task_ref[i] > 0 or (task_ref[i] == 0 and sum(task_choices_minus_1[i])<0) : # ref in A_right, ground_truth in A_left, target choices in B_left\n",
    "        if not os.path.exists('./task_train/'+str_i):\n",
    "            os.mkdir('./task_train/'+str_i)\n",
    "            \n",
    "        cv2.imwrite('./task_train/'+str_i+\"/reference\" + \".jpg\", im_A_right[i])\n",
    "        gt_id = random.randint(0, num_choice-1) # randomly set up gt_id from {0, 1, 2, ...., num_choice-1}\n",
    "        \n",
    "        cv2.imwrite('./task_train/'+str_i+\"/choice_\" + str(gt_id) + \".jpg\", im_A_left[i])\n",
    "        gt_train.append([str_i, str(gt_id)])\n",
    "        \n",
    "        for choice_i in range(num_choice):\n",
    "            if choice_i < gt_id:\n",
    "                cv2.imwrite('./task_train/'+str_i+\"/choice_\"+str(choice_i)+ \".jpg\", im_B_left[task_choices_minus_1[i][choice_i] * (-1)])\n",
    "            elif choice_i > gt_id:\n",
    "                cv2.imwrite('./task_train/'+str_i+\"/choice_\"+str(choice_i)+ \".jpg\", im_B_left[task_choices_minus_1[i][choice_i-1] * (-1)])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['000000000', '1'], ['000000001', '8'], ['000000002', '9'], ['000000003', '0'], ['000000004', '7'], ['000000005', '9'], ['000000006', '4'], ['000000007', '2'], ['000000008', '9'], ['000000009', '6'], ['000000010', '5'], ['000000011', '4'], ['000000012', '1'], ['000000013', '6'], ['000000014', '7'], ['000000015', '6']]\n",
      "29757\n"
     ]
    }
   ],
   "source": [
    "print(gt_train[:16])\n",
    "print(len(gt_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"gt_train.csv\",\"w+\") as my_csv:            # writing the file as my_csv\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',')  # using the csv module to write the file\n",
    "    csvWriter.writerows(gt_train)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
