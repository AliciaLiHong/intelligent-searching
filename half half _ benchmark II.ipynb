{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set is from coco train 2017, there are totally 118,287 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the data into two non-overlapping parts: part-A (~30%) and part-B (~70%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name_list = glob.glob('train2017/*.jpg') # the whole image dataset, 118287 images\n",
    "\n",
    "image_part_A, image_part_B = train_test_split(image_name_list, test_size = 0.7)\n",
    "\n",
    "# 35486 images in part_A, 82801 images in part_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop out halves for all images in both parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_A_left = []\n",
    "im_A_right = []\n",
    "hist_A_left = []\n",
    "hist_A_right = []\n",
    "\n",
    "H_least = 300   # images larger than (H_least, W_least) are not resized\n",
    "W_least = 500   # others resized to (H_least, W_least)\n",
    "\n",
    "for i in range(min(len(image_part_A), 12000)): \n",
    "    im = cv2.imread(image_part_A[i])\n",
    "    \n",
    "    if im.shape[0] > H_least and im.shape[1] > W_least: # Try to find images that are large enough to have 224x224 crops from the two halves\n",
    "        left_x = random.randint(0, im.shape[1]//2 - 224)  # Crop out boundaries (rather than simply cut image into halves) to avoid simply continuity clue\n",
    "        left_y = random.randint(0, im.shape[0] - 224)\n",
    "        im_l = im[left_y:left_y+224, left_x:left_x+224]  # y:y+h, x:x+w\n",
    "        im_A_left.append(im_l) \n",
    "        \n",
    "        \n",
    "        right_x = random.randint(im.shape[1]//2, im.shape[1]-224)\n",
    "        right_y = random.randint(0, im.shape[0] - 224)\n",
    "        im_r = im[right_y:right_y+224, right_x:right_x+224]\n",
    "        #print(im.shape,im_l.shape,im_r.shape)\n",
    "        im_A_right.append(im_r)\n",
    "        \n",
    "\n",
    "        hist_A_left.append(cv2.calcHist([im_l], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]))\n",
    "        hist_A_right.append(cv2.calcHist([im_r], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]))  \n",
    "    \n",
    "    else:\n",
    "        im = cv2.resize(im, (W_least, H_least))  # resize the images that are not large enough to (300, 500)\n",
    "        left_x = random.randint(0, im.shape[1]//2 - 224)  # Crop out boundaries (rather than simply cut image into halves) to avoid simply continuity clue\n",
    "        left_y = random.randint(0, im.shape[0] - 224)\n",
    "        im_l = im[left_y:left_y+224, left_x:left_x+224]\n",
    "        \n",
    "        im_A_left.append(im_l) # y:y+h, x:x+w\n",
    "        \n",
    "        \n",
    "        right_x = random.randint(im.shape[1]//2, im.shape[1]-224)\n",
    "        right_y = random.randint(0, im.shape[0] - 224)\n",
    "        im_r = im[right_y:right_y+224, right_x:right_x+224]\n",
    "        #print(im.shape,im_l.shape,im_r.shape)\n",
    "        im_A_right.append(im_r)\n",
    "        \n",
    "\n",
    "        hist_A_left.append(cv2.calcHist([im_l], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]))\n",
    "        hist_A_right.append(cv2.calcHist([im_r], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_B_left = []\n",
    "im_B_right = []\n",
    "hist_B_left = []\n",
    "hist_B_right = []\n",
    "\n",
    "for i in range(min(len(image_part_B), 28000)): \n",
    "    im = cv2.imread(image_part_B[i])\n",
    "    \n",
    "    if im.shape[0] > H_least and im.shape[1] > W_least: # Try to find images that are large enough to have 224x224 crops from the two halves\n",
    "        left_x = random.randint(0, im.shape[1]//2 - 224)  # Crop out boundaries (rather than simply cut image into halves) to avoid simply continuity clue\n",
    "        left_y = random.randint(0, im.shape[0] - 224)\n",
    "        im_l = im[left_y:left_y+224, left_x:left_x+224]\n",
    "        im_B_left.append(im_l) # y:y+h, x:x+w\n",
    "        \n",
    "        \n",
    "        right_x = random.randint(im.shape[1]//2, im.shape[1]-224)\n",
    "        right_y = random.randint(0, im.shape[0] - 224)\n",
    "        im_r = im[right_y:right_y+224, right_x:right_x+224]\n",
    "        im_B_right.append(im_r)\n",
    "        #print(im.shape,im_l.shape,im_r.shape)\n",
    "\n",
    "        hist_B_left.append(cv2.calcHist([im_l], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]))\n",
    "        hist_B_right.append(cv2.calcHist([im_r], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]))  \n",
    "    \n",
    "    else:\n",
    "        im = cv2.resize(im, (W_least, H_least))  # resize the images that are not large enough to (300, 500)\n",
    "        left_x = random.randint(0, im.shape[1]//2 - 224)  # Crop out boundaries (rather than simply cut image into halves) to avoid simply continuity clue\n",
    "        left_y = random.randint(0, im.shape[0] - 224)\n",
    "        im_l = im[left_y:left_y+224, left_x:left_x+224]\n",
    "        im_B_left.append(im_l) # y:y+h, x:x+w\n",
    "        \n",
    "        \n",
    "        right_x = random.randint(im.shape[1]//2, im.shape[1]-224)\n",
    "        right_y = random.randint(0, im.shape[0] - 224)\n",
    "        im_r = im[right_y:right_y+224, right_x:right_x+224]\n",
    "        im_B_right.append(im_r)\n",
    "        #print(im.shape,im_l.shape,im_r.shape)\n",
    "\n",
    "        hist_B_left.append(cv2.calcHist([im_l], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]))\n",
    "        hist_B_right.append(cv2.calcHist([im_r], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tBuild a task case for each image in part-A:\n",
    "\n",
    "o\trandomly pick a half (left/right) as the reference image and the other half as the ground-truth target image \n",
    "\n",
    "o\tfrom all images in part-B (only consider the \"correct\" side, e.g. if the reference image is from the left side, use only right side of the part-B images), randomly sample (#Choices-1) of them that are among the top K in terms of color histogram similarity from the GT target image. \n",
    "\n",
    "o\tsave the task as task_i = <ref_img, <choices>, gt_idx>, where <choices> are shuffled (#Choices-1) image halves from part-B together with the target image, and 'gt_idx' is the index of the target image within <choices>. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ref = len(im_A_left)\n",
    "num_B = len(im_B_left)\n",
    "compare_method = 3 # means that the smaller the compareHist, the similar\n",
    "num_choice = 10\n",
    "K = 100\n",
    "\n",
    "task_ref = []  # \n",
    "task_tgt = []  #\n",
    "task_choices_minus_1 = []\n",
    "\n",
    "for i_ref in range(num_ref):\n",
    "    lr = np.random.randint(2)\n",
    "    if lr == 0:  # pick left half as the reference image\n",
    "        task_ref.append(-1*i_ref)  # negative value means ref images are picked from left\n",
    "        task_tgt.append(i_ref)     # positive value means tgt images are picked from right\n",
    "        \n",
    "        hist_Comp = []\n",
    "        for j in range(num_B):     # ref in A_left, choices in B_right\n",
    "            halfi_halfj = cv2.compareHist(hist_A_left[i_ref], hist_B_right[j], compare_method)\n",
    "            hist_Comp.append(halfi_halfj)\n",
    "        \n",
    "        # the top K in terms of color histogram similarity from the GT target image.\n",
    "        matchest_topK = np.argpartition(np.array(hist_Comp),K)[:K]  \n",
    "        # randomly sample (#Choices-1) among the top K\n",
    "        arg_choices_minus_1 = np.random.choice(K, num_choice-1, replace=False)\n",
    "        choices_minus_1 = matchest_topK[arg_choices_minus_1]\n",
    "        task_choices_minus_1.append(choices_minus_1)      # choices in B_right, positive\n",
    "    \n",
    "    else:        # pick right half as the reference image\n",
    "        task_ref.append(i_ref)          # positive value means ref images are picked from right\n",
    "        task_tgt.append(-1*i_ref)       # negative value means tgt images are picked from left\n",
    "        \n",
    "        hist_Comp = []\n",
    "        for j in range(num_B):         # ref in A_right, choices in B_left\n",
    "            halfi_halfj = cv2.compareHist(hist_A_right[i_ref], hist_B_left[j], compare_method)\n",
    "            hist_Comp.append(halfi_halfj)\n",
    "        \n",
    "        matchest_topK = np.argpartition(np.array(hist_Comp),K)[:K]  \n",
    "        arg_choices_minus_1 = np.random.choice(K, num_choice-1, replace=False)\n",
    "        choices_minus_1 = matchest_topK[arg_choices_minus_1]\n",
    "        task_choices_minus_1.append(choices_minus_1 * (-1))  # choices in B_left, negative value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 [25273  9669 13902 25968 18037  6039  9597  5832 25923]\n",
      "1 -1 [ -8825  -3223 -21979  -1810  -2898  -8666 -11967 -27008 -15255]\n",
      "-2 2 [ 1085 18456 10811  5219 15971 18980 18273  3249  2850]\n",
      "3 -3 [-18211 -15821 -22868 -16873  -5372 -18096 -24643 -17479 -24265]\n",
      "4 -4 [-13210 -14021 -13638 -24850  -7478  -8205  -5089  -3521  -5538]\n"
     ]
    }
   ],
   "source": [
    "for i in range(min(num_ref,5)):\n",
    "    print(task_ref[i], task_tgt[i], task_choices_minus_1[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few task samples once you are done with this. We might also want to use more carefully picked images (indoor scenes, e.g. from topic models, or scenes in general) later, depending on how challenging this initial benchmark looks like. \n",
    "\n",
    "A good folder structure can be having one folder for each sample containing the reference image together with all choices: \n",
    "sample_id/\n",
    " - reference.png\n",
    " - choice_0.png\n",
    " - choice_1.png\n",
    " ...\n",
    " - choice_9.png\n",
    "\n",
    "The ground-truth can be saved in a single .txt file with two columns: sample_id and true_choice_idx. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_num = len(im_A_left)\n",
    "samples_num = 30 # take samples_num of samples to show the results\n",
    "import os\n",
    "if not os.path.exists('./task'):\n",
    "    os.mkdir('./task')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(min(task_num, samples_num)):\n",
    "    if task_ref[i] < 0 or (task_ref[i] == 0 and sum(task_choices_minus_1[i])>0): # ref in A_left, ground_truth in A_right, target choices in B_right\n",
    "        \n",
    "        if not os.path.exists('./task/sample_'+str(i)):\n",
    "            os.mkdir('./task/sample_'+str(i))\n",
    "            \n",
    "        cv2.imwrite('./task/sample_'+str(i)+\"/reference\" + \".jpg\", im_A_left[i])\n",
    "        cv2.imwrite('./task/sample_'+str(i)+\"/choice_\" + str(num_choice-1) + \".jpg\", im_A_right[i])\n",
    "        \n",
    "        for choice_i in range(num_choice-1):\n",
    "            cv2.imwrite('./task/sample_'+str(i)+\"/choice_\"+str(choice_i)+ \".jpg\", im_B_right[task_choices_minus_1[i][choice_i]])\n",
    "        \n",
    "    \n",
    "    elif task_ref[i] > 0 or (task_ref[i] == 0 and sum(task_choices_minus_1[i])<0) : # ref in A_right, ground_truth in A_left, target choices in B_left\n",
    "        if not os.path.exists('./task/sample_'+str(i)):\n",
    "            os.mkdir('./task/sample_'+str(i))\n",
    "            \n",
    "        cv2.imwrite('./task/sample_'+str(i)+\"/reference\" + \".jpg\", im_A_right[i])\n",
    "        cv2.imwrite('./task/sample_'+str(i)+\"/choice_\" + str(num_choice-1) + \".jpg\", im_A_left[i])\n",
    "        \n",
    "        for choice_i in range(num_choice-1):\n",
    "            cv2.imwrite('./task/sample_'+str(i)+\"/choice_\"+str(choice_i)+ \".jpg\", im_B_left[task_choices_minus_1[i][choice_i] * (-1)])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
