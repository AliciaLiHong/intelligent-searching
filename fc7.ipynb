{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import os\n",
    "from pylab import *\n",
    "import numpy as np\n",
    "from tensorflow.python.ops import nn_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "import time\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "import matplotlib.image as mpimg\n",
    "from scipy.ndimage import filters\n",
    "import urllib\n",
    "from numpy import random\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#from caffe_classes import class_names\n",
    "\n",
    "train_x = zeros((1, 227,227,3)).astype(float32)\n",
    "train_y = zeros((1, 1000))\n",
    "xdim = train_x.shape[1:]\n",
    "ydim = train_y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/mac/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "im1 = (imread(\"laska.png\")[:,:,:3]).astype(float32)\n",
    "im1 = im1 - mean(im1)\n",
    "im1[:, :, 0], im1[:, :, 2] = im1[:, :, 2], im1[:, :, 0]\n",
    "\n",
    "im2 = (imread(\"poodle.png\")[:,:,:3]).astype(float32)\n",
    "im2[:, :, 0], im2[:, :, 2] = im2[:, :, 2], im2[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_data = load(open(\"bvlc_alexnet.npy\", \"rb\"), encoding=\"latin1\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(input, kernel, biases, k_h, k_w, c_o, s_h, s_w,  padding=\"VALID\", group=1):\n",
    "    '''From https://github.com/ethereon/caffe-tensorflow\n",
    "    '''\n",
    "    c_i = input.get_shape()[-1]\n",
    "    assert c_i%group==0\n",
    "    assert c_o%group==0\n",
    "    convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\n",
    "    \n",
    "    \n",
    "    if group==1:\n",
    "        conv = convolve(input, kernel)\n",
    "    else:\n",
    "        #tf.split(value, num_or_size_splits, axis) -- new version\n",
    "        ## tf.split(axis, num_or_size_splits, value) -- old version\n",
    "        \n",
    "        #input_groups = tf.split(3, group, input)\n",
    "        #kernel_groups = tf.split(3, group, kernel)\n",
    "        \n",
    "        input_groups = tf.split(input, group, 3)\n",
    "        kernel_groups = tf.split(kernel, group, 3)\n",
    "        \n",
    "        output_groups = [convolve(i, k) for i,k in zip(input_groups, kernel_groups)]\n",
    "        conv = tf.concat( output_groups, 3)\n",
    "    return  tf.reshape(tf.nn.bias_add(conv, biases), [-1]+conv.get_shape().as_list()[1:])\n",
    "\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None,) + xdim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor input_im_ind in range(output.shape[0]):\\n    inds = argsort(output)[input_im_ind,:]\\n    print \"Image\", input_im_ind\\n    for i in range(5):\\n        print class_names[inds[-1-i]], output[input_im_ind, inds[-1-i]]\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_h = 11; k_w = 11; c_o = 96; s_h = 4; s_w = 4\n",
    "conv1W = tf.Variable(net_data[\"conv1\"][0])\n",
    "conv1b = tf.Variable(net_data[\"conv1\"][1])\n",
    "conv1_in = conv(x, conv1W, conv1b, k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=1)\n",
    "conv1 = tf.nn.relu(conv1_in)\n",
    "\n",
    "#lrn1\n",
    "#lrn(2, 2e-05, 0.75, name='norm1')\n",
    "radius = 2; alpha = 2e-05; beta = 0.75; bias = 1.0\n",
    "lrn1 = tf.nn.local_response_normalization(conv1,\n",
    "                                                  depth_radius=radius,\n",
    "                                                  alpha=alpha,\n",
    "                                                  beta=beta,\n",
    "                                                  bias=bias)\n",
    "\n",
    "#maxpool1\n",
    "#max_pool(3, 3, 2, 2, padding='VALID', name='pool1')\n",
    "k_h = 3; k_w = 3; s_h = 2; s_w = 2; padding = 'VALID'\n",
    "maxpool1 = tf.nn.max_pool(lrn1, ksize=[1, k_h, k_w, 1], strides=[1, s_h, s_w, 1], padding=padding)\n",
    "\n",
    "\n",
    "#conv2\n",
    "#conv(5, 5, 256, 1, 1, group=2, name='conv2')\n",
    "k_h = 5; k_w = 5; c_o = 256; s_h = 1; s_w = 1; group = 2\n",
    "conv2W = tf.Variable(net_data[\"conv2\"][0])\n",
    "conv2b = tf.Variable(net_data[\"conv2\"][1])\n",
    "conv2_in = conv(maxpool1, conv2W, conv2b, k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
    "conv2 = tf.nn.relu(conv2_in)\n",
    "\n",
    "\n",
    "#lrn2\n",
    "#lrn(2, 2e-05, 0.75, name='norm2')\n",
    "radius = 2; alpha = 2e-05; beta = 0.75; bias = 1.0\n",
    "lrn2 = tf.nn.local_response_normalization(conv2,\n",
    "                                                  depth_radius=radius,\n",
    "                                                  alpha=alpha,\n",
    "                                                  beta=beta,\n",
    "                                                  bias=bias)\n",
    "\n",
    "#maxpool2\n",
    "#max_pool(3, 3, 2, 2, padding='VALID', name='pool2')                                                  \n",
    "k_h = 3; k_w = 3; s_h = 2; s_w = 2; padding = 'VALID'\n",
    "maxpool2 = tf.nn.max_pool(lrn2, ksize=[1, k_h, k_w, 1], strides=[1, s_h, s_w, 1], padding=padding)\n",
    "\n",
    "#conv3\n",
    "#conv(3, 3, 384, 1, 1, name='conv3')\n",
    "k_h = 3; k_w = 3; c_o = 384; s_h = 1; s_w = 1; group = 1\n",
    "conv3W = tf.Variable(net_data[\"conv3\"][0])\n",
    "conv3b = tf.Variable(net_data[\"conv3\"][1])\n",
    "conv3_in = conv(maxpool2, conv3W, conv3b, k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
    "conv3 = tf.nn.relu(conv3_in)\n",
    "\n",
    "#conv4\n",
    "#conv(3, 3, 384, 1, 1, group=2, name='conv4')\n",
    "k_h = 3; k_w = 3; c_o = 384; s_h = 1; s_w = 1; group = 2\n",
    "conv4W = tf.Variable(net_data[\"conv4\"][0])\n",
    "conv4b = tf.Variable(net_data[\"conv4\"][1])\n",
    "conv4_in = conv(conv3, conv4W, conv4b, k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
    "conv4 = tf.nn.relu(conv4_in)\n",
    "\n",
    "\n",
    "#conv5\n",
    "#conv(3, 3, 256, 1, 1, group=2, name='conv5')\n",
    "k_h = 3; k_w = 3; c_o = 256; s_h = 1; s_w = 1; group = 2\n",
    "conv5W = tf.Variable(net_data[\"conv5\"][0])\n",
    "conv5b = tf.Variable(net_data[\"conv5\"][1])\n",
    "conv5_in = conv(conv4, conv5W, conv5b, k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
    "conv5 = tf.nn.relu(conv5_in)\n",
    "\n",
    "#maxpool5\n",
    "#max_pool(3, 3, 2, 2, padding='VALID', name='pool5')\n",
    "k_h = 3; k_w = 3; s_h = 2; s_w = 2; padding = 'VALID'\n",
    "maxpool5 = tf.nn.max_pool(conv5, ksize=[1, k_h, k_w, 1], strides=[1, s_h, s_w, 1], padding=padding)\n",
    "\n",
    "#fc6\n",
    "#fc(4096, name='fc6')\n",
    "fc6W = tf.Variable(net_data[\"fc6\"][0])\n",
    "fc6b = tf.Variable(net_data[\"fc6\"][1])\n",
    "fc6 = tf.nn.relu_layer(tf.reshape(maxpool5, [-1, int(prod(maxpool5.get_shape()[1:]))]), fc6W, fc6b)\n",
    "\n",
    "#fc7\n",
    "#fc(4096, name='fc7')\n",
    "fc7W = tf.Variable(net_data[\"fc7\"][0])\n",
    "fc7b = tf.Variable(net_data[\"fc7\"][1])\n",
    "fc7 = tf.nn.relu_layer(fc6, fc7W, fc7b)\n",
    "\n",
    "fc7_xw_plus_b = nn_ops.bias_add(math_ops.matmul(fc6, fc7W), fc7b)\n",
    "\n",
    "\n",
    "fc7_after_relu = nn_ops.relu(fc7_xw_plus_b)\n",
    "\n",
    "\n",
    "#fc8\n",
    "#fc(1000, relu=False, name='fc8')\n",
    "fc8W = tf.Variable(net_data[\"fc8\"][0])\n",
    "fc8b = tf.Variable(net_data[\"fc8\"][1])\n",
    "fc8 = tf.nn.xw_plus_b(fc7, fc8W, fc8b)\n",
    "\n",
    "\n",
    "#prob\n",
    "#softmax(name='prob'))\n",
    "prob = tf.nn.softmax(fc8)\n",
    "\n",
    "#init = tf.initialize_all_variables()\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "t = time.time()\n",
    "#output = sess.run(prob, feed_dict = {x:[im1,im2]})\n",
    "################################################################################\n",
    "\n",
    "#fc7_xw_plus_b_output = sess.run(fc7_xw_plus_b, feed_dict = {x:[im1,im2]})\n",
    "\n",
    "#Output:\n",
    "'''\n",
    "for input_im_ind in range(output.shape[0]):\n",
    "    inds = argsort(output)[input_im_ind,:]\n",
    "    print \"Image\", input_im_ind\n",
    "    for i in range(5):\n",
    "        print class_names[inds[-1-i]], output[input_im_ind, inds[-1-i]]\n",
    "'''\n",
    "#print 'two-step ReLu:',fc7_xw_plus_b_output[1,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet.ipynb                          poodle.png\r\n",
      "Untitled.ipynb                         ref_im_fc7.npy\r\n",
      "Visual.ipynb                           \u001b[34mtask_test\u001b[m\u001b[m/\r\n",
      "\u001b[34malexnet_imagenet_distribution\u001b[m\u001b[m/         \u001b[34mtask_train\u001b[m\u001b[m/\r\n",
      "bvlc_alexnet.npy                       test_image.jpg\r\n",
      "caffe_classes.py                       test_part_A.npy\r\n",
      "cal_comp_hist.ipynb                    test_part_B.npy\r\n",
      "crop.ipynb                             test_set.npy\r\n",
      "cute.jpg                               tgt_im_fc7.npy\r\n",
      "gt_test.csv                            train test AB dividing.ipynb\r\n",
      "gt_train.csv                           \u001b[34mtrain2017\u001b[m\u001b[m/\r\n",
      "half half _ benchmark II-test.ipynb    train_part_A.npy\r\n",
      "half half _ benchmark II-train.ipynb   train_part_B.npy\r\n",
      "half half _ benchmark II.ipynb         train_set.npy\r\n",
      "half half _ benchmark.ipynb            train_task_choices_minus_1.npy\r\n",
      "intelligent searching Li's part.ipynb  train_task_ref.npy\r\n",
      "laska.png                              train_task_tgt.npy\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  app.launch_new_instance()\n",
      "/Users/mac/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/Users/mac/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/Users/mac/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:29: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1999, 227, 227, 3)\n",
      "(1999, 10, 227, 227, 3)\n",
      "(1999, 4096)\n",
      "(1999, 10, 4096)\n"
     ]
    }
   ],
   "source": [
    "ref_im_list = []\n",
    "tgt_im_list = []\n",
    "\n",
    "num_choices = 10\n",
    "cnt = 0\n",
    "\n",
    "ref_im_fc7 = []\n",
    "tgt_im_fc7 = []\n",
    "\n",
    "for sample in os.listdir('task_train/'):\n",
    "    if cnt == 2000:\n",
    "        break\n",
    "        \n",
    "    if sample != '.DS_Store' and sample != 'README.md':\n",
    "        ref_im_name = 'task_train/' +sample+ '/reference.jpg'\n",
    "        ref_im = imread(ref_im_name)\n",
    "        ref_im = imresize(ref_im,(227,227,3))\n",
    "        ref_im = (ref_im[:,:,:3]).astype(float32)\n",
    "        ref_im = ref_im - mean(ref_im)\n",
    "        ref_im[:, :, 0], ref_im[:, :, 2] = ref_im[:, :, 2], ref_im[:, :, 0]\n",
    "        ref_im_list.append(ref_im)\n",
    "    \n",
    "        tmp_tgt_im_list = []\n",
    "        tmp_tgt_im_fc7  = []\n",
    "        \n",
    "        for i in range(num_choices):\n",
    "            tgt_im_name = 'task_train/' +sample+ '/choice_' + str(i) + '.jpg'\n",
    "            tgt_im = imread(tgt_im_name)\n",
    "            tgt_im = imresize(tgt_im, (227,227,3))\n",
    "            tgt_im = (tgt_im[:,:,:3]).astype(float32)\n",
    "            tgt_im = tgt_im - mean(tgt_im)\n",
    "            tgt_im[:, :, 0], tgt_im[:, :, 2] = tgt_im[:, :, 2], tgt_im[:, :, 0]\n",
    "            tmp_tgt_im_list.append(tgt_im)\n",
    "        \n",
    "        tmp_tgt_im_fc7 = sess.run(fc7_xw_plus_b, feed_dict = {x:tmp_tgt_im_list})\n",
    "        \n",
    "        tgt_im_list.append(tmp_tgt_im_list)\n",
    "        tgt_im_fc7.append(tmp_tgt_im_fc7)\n",
    "        \n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "ref_im_fc7 = sess.run(fc7_xw_plus_b, feed_dict = {x:ref_im_list})\n",
    "\n",
    "ref_im_list = np.array(ref_im_list)\n",
    "tgt_im_list = np.array(tgt_im_list)\n",
    "ref_im_fc7 = np.array(ref_im_fc7)\n",
    "tgt_im_fc7 = np.array(tgt_im_fc7)\n",
    "\n",
    "print(ref_im_list.shape)\n",
    "print(tgt_im_list.shape) \n",
    "print(ref_im_fc7.shape)\n",
    "print(tgt_im_fc7.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ref_im_fc7.npy', ref_im_fc7)\n",
    "np.save('tgt_im_fc7.npy', tgt_im_fc7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
